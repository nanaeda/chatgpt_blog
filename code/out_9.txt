Namespace(sft_model_path='gen/sft_model', ranked_sample_path='gen/ranked_answers.txt', learning_rate=0.0001, bpe_path='data/bpe.txt', device='cuda', model_output_path='gen/reward_model', num_answers_per_query=5)
loaded 89 data points
-------- token manager validation --------
vocab size: 16387
tokens for ダイヤモンド: [15268]
tokens for 北海道: [9957]
tokens for 一石二鳥: [8572, 431, 2850, 382]
[begin]こんにちは[unk]こんばんは。[sep]
-------- end --------

tain base gpt
step    0 (   0 sec): loss=7.717123, scores=[3.099367  3.1503592 3.1928701 3.0425956 3.2864084]
step   10 (   2 sec): loss=7.549097, scores=[0.3302857  0.28050023 0.49943855 0.53894544 0.3730066 ]
step   20 (   4 sec): loss=7.239554, scores=[0.7414569  0.7414569  0.74914414 0.74914414 0.7328034 ]
step   30 (   7 sec): loss=7.021618, scores=[0.45659015 0.73791724 0.7746004  0.9993147  0.11619361]
step   40 (   9 sec): loss=6.955870, scores=[-0.73542345 -0.812726   -0.7944742  -0.7207829  -0.76408094]
step   50 (  11 sec): loss=6.841827, scores=[-0.10934822  0.20431079  0.4612164   0.16346447  0.39611876]
step   60 (  14 sec): loss=6.561439, scores=[ 4.215283    2.6776392   1.1009802  -0.06387887 -0.20200427]
step   70 (  16 sec): loss=6.531225, scores=[ 2.2825239   0.92181605  1.9677014  -4.390525   -3.0863388 ]
step   80 (  18 sec): loss=6.545630, scores=[-0.21044816  0.29298034 -0.7407253   0.00438503  0.1702282 ]
step   90 (  20 sec): loss=6.478943, scores=[2.332652  2.343555  1.4628876 2.9087315 3.9544415]
step  100 (  23 sec): loss=6.429664, scores=[0.7033963  0.6603007  0.5085544  0.51835257 0.2972024 ]
step  110 (  25 sec): loss=6.490422, scores=[0.88504946 0.88504946 0.82018316 0.85781795 0.8359923 ]
step  120 (  27 sec): loss=6.453084, scores=[-0.78244513 -0.5648868  -0.6734403  -0.24693407 -1.1065863 ]
step  130 (  29 sec): loss=6.108784, scores=[ 2.6853285 -0.3349858  1.1286379 -0.5805015 -0.8841276]
step  140 (  32 sec): loss=6.182971, scores=[1.2023878 1.7148702 1.7136449 1.4314659 1.3590527]
step  150 (  34 sec): loss=6.138970, scores=[2.9586256  2.9586256  3.5280182  1.4591668  0.35341692]
step  160 (  36 sec): loss=5.944434, scores=[ 1.9635856   1.8309579   0.59153444  1.8116832  -0.9518845 ]
step  170 (  39 sec): loss=5.805135, scores=[ 0.16188432 -0.21109195  0.11450307 -0.5936047  -0.19568773]
step  180 (  41 sec): loss=5.699591, scores=[ 1.0525304   0.45977965  0.3114225  -1.8013908  -1.6693201 ]
step  190 (  43 sec): loss=5.479422, scores=[ 2.2888389  0.6636385 -0.9393712 -0.9653043 -1.5456127]
step  200 (  45 sec): loss=5.322678, scores=[0.07915924 2.025262   0.9131967  1.8632593  1.6199677 ]
step  210 (  48 sec): loss=5.002642, scores=[ 1.3622077  1.1569867 -0.8344171 -0.9883858 -2.5391536]
step  220 (  50 sec): loss=4.731573, scores=[ 2.2547517   0.18114406  0.644271   -0.8737707  -1.0068808 ]
step  230 (  52 sec): loss=4.830406, scores=[2.3883288  1.2104028  0.9846218  0.71817285 0.75923616]
step  240 (  54 sec): loss=4.363423, scores=[ 8.1461210e+00  2.7996473e+00  1.4801902e+00 -1.6498487e-03
 -8.9461975e-02]
step  250 (  57 sec): loss=4.086732, scores=[ 2.7786245  1.7952727  1.4235264 -1.2197078 -1.3025255]
step  260 (  59 sec): loss=4.062267, scores=[-1.1511347 -1.1229234 -1.2886789 -1.5351748 -1.6942314]
step  270 (  61 sec): loss=4.219333, scores=[ 0.0352907  -1.1040467  -0.69029623 -1.4752388  -1.6578045 ]
step  280 (  63 sec): loss=3.848133, scores=[ 4.2511783   2.7910404  -0.18874685 -1.7131202  -2.8336656 ]
step  290 (  66 sec): loss=3.987606, scores=[ 2.5475802   2.3868325  -1.6241839  -0.03471307 -0.750293  ]
step  300 (  68 sec): loss=3.899773, scores=[ 2.7032416  -0.81565285 -1.8405763  -3.786476   -5.328706  ]
step  310 (  70 sec): loss=3.969501, scores=[-0.21985488 -0.4853026  -0.6803581  -2.367465   -3.3818681 ]
step  320 (  73 sec): loss=3.513721, scores=[-1.0950838  -1.5633329  -0.85966027 -3.4085162  -2.9691982 ]
step  330 (  75 sec): loss=3.473934, scores=[ 3.6559715   2.4039268  -1.2343814  -0.37749138 -7.717879  ]
step  340 (  77 sec): loss=3.196752, scores=[ 0.36776364 -2.9083533  -2.6285207  -3.1875684  -5.2893276 ]
step  350 (  79 sec): loss=3.197756, scores=[-1.0808431 -0.6691243 -0.8438598 -1.8100197 -2.7186308]
step  360 (  81 sec): loss=2.864059, scores=[ 0.89773375  1.0050253   1.0612311   0.26304966 -2.4226882 ]
step  370 (  84 sec): loss=2.733011, scores=[ 0.5197161   0.5298223   0.18278158 -3.071981   -3.015777  ]
step  380 (  86 sec): loss=2.777230, scores=[ 1.7647192   0.62975174 -0.29609704 -1.2207392  -2.3345883 ]
step  390 (  88 sec): loss=3.026455, scores=[ 1.8009863   1.2119396  -0.6996053  -0.94768953 -2.6376798 ]
step  400 (  91 sec): loss=2.944625, scores=[ 2.9884524   0.90229166 -0.91483223 -3.584933   -5.3582983 ]
step  410 (  93 sec): loss=2.837715, scores=[ 5.445946    3.836326    2.733896    1.3727828  -0.47122842]
step  420 (  95 sec): loss=2.736236, scores=[ 3.8500476  3.0880282  1.3998151 -4.1636615 -4.426459 ]
step  430 (  97 sec): loss=2.539323, scores=[ 4.6225667  1.6775953 -1.013129  -3.6689453 -4.464706 ]
step  440 ( 100 sec): loss=2.154376, scores=[ 4.7352715 -0.824138  -0.6853903  0.574473  -1.7303392]
step  450 ( 102 sec): loss=1.898204, scores=[ 5.17465    3.4885178  1.3219708 -2.5674725 -4.0350356]
step  460 ( 104 sec): loss=1.844212, scores=[ 8.349979    2.7543368   3.0421162   0.01325967 -4.315921  ]
step  470 ( 106 sec): loss=1.889034, scores=[ 0.9017344   1.7256448  -1.6392016  -1.4797165  -0.32929355]
step  480 ( 108 sec): loss=1.778927, scores=[ 4.933032   4.420226  -1.0163296 -1.8695751 -2.9579737]
step  490 ( 111 sec): loss=1.909146, scores=[ 0.54464537 -0.13803186 -0.86706096 -1.2138042  -3.9256196 ]
step  500 ( 113 sec): loss=2.183755, scores=[ 5.3242407  5.305419   5.1303725  4.4740124 -1.1054671]
step  510 ( 115 sec): loss=2.201391, scores=[ 3.4782922  4.576079  -2.2263048 -2.2187903 -3.417208 ]
step  520 ( 118 sec): loss=2.200320, scores=[ 2.7769227  1.2152421 -1.899953  -3.4973135 -3.9076993]
step  530 ( 120 sec): loss=2.296244, scores=[ 2.159238  -0.3893141 -2.2086253 -2.9163587 -5.6219673]
step  540 ( 122 sec): loss=2.120227, scores=[ 5.576704    5.7399154   0.47533658 -0.14530583 -1.8829583 ]
step  550 ( 124 sec): loss=1.930569, scores=[ 3.674754   3.488752   1.8312505  1.0409033 -2.4519486]
step  560 ( 127 sec): loss=1.934035, scores=[ 3.5770311  1.3052938 -0.5352435 -2.9937732 -4.2825828]
step  570 ( 129 sec): loss=1.907635, scores=[ 1.5243927   0.63395894 -0.7070211  -2.338153   -2.914442  ]
step  580 ( 131 sec): loss=1.809455, scores=[ 3.922447    1.7245387   0.30348247 -0.092182   -3.3626332 ]
step  590 ( 133 sec): loss=1.854265, scores=[ 1.3222413  1.3222413  1.3222413 -2.1691782 -5.2742605]
step  600 ( 135 sec): loss=1.826609, scores=[ 3.2460008   2.328236   -0.88225913 -1.8541739  -4.27939   ]
